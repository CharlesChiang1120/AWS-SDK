{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "\n",
    "#Client\n",
    "athena = boto3.client('athena')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "#Env\n",
    "output_bucket = os.environ['Athena_Output']\n",
    "chunk = os.environ['chunk']\n",
    "upload_bucket = os.environ['BUCKET_NAME']\n",
    "\n",
    "#Empty List\n",
    "query_id_list = []\n",
    "\n",
    "#Yesterday Date                                             \n",
    "yesterday = datetime.now() - timedelta(days=1)\n",
    "\n",
    "#Main Function\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    #SQL Query\n",
    "    sql_query = '''\n",
    "       with clordtrail_log AS (\n",
    "            SELECT\n",
    "            json_extract(responseelements,\n",
    "            '$.queryExecutionId') AS query_id,\n",
    "            from_iso8601_timestamp(eventtime) AS datetime\n",
    "            FROM    \n",
    "            WHERE   eventsource='athena.amazonaws.com'\n",
    "            AND eventname='StartQueryExecution'\n",
    "            AND json_extract(responseelements, '$.queryExecutionId') is NOT null)\n",
    "            SELECT *\n",
    "            FROM   clordtrail_log\n",
    "            WHERE  datetime > date_add('day',-1,now() )'''\n",
    "    \n",
    "    #Partition\n",
    "    s3_output = 's3://{}/{}/{}/{}/'.format(output_bucket,yesterday.year,yesterday.month,yesterday.day)  \n",
    "    \n",
    "    #Athena Query\n",
    "    batch_query_id = run_query(sql_query,s3_output, max_execution=5)\n",
    "    \n",
    "    #batch_get_query_execution limited 50 query id\n",
    "    #Split List into chunk \n",
    "    batch_query_chunks = list(divide_chunks(batch_query_id, 50))\n",
    "    \n",
    "    batch_query(batch_query_chunks)\n",
    "    \n",
    "def run_query(query, s3_output, max_execution=5):\n",
    "    \n",
    "    #Run SQL Query\n",
    "    response = athena.start_query_execution(\n",
    "                                    QueryString=query,\n",
    "                                    ResultConfiguration={\n",
    "                                    'OutputLocation': s3_output\n",
    "                                                        }\n",
    "                                                )\n",
    "\n",
    "    #Query ID\n",
    "    execution_id = response['QueryExecutionId']\n",
    "    \n",
    "    print(\"QueryExecutionId = \" + str(execution_id))\n",
    "    \n",
    "    state  = 'QUEUED'\n",
    "\n",
    "    while (max_execution > 0 and state in ['RUNNING', 'QUEUED']):\n",
    "        max_execution = max_execution - 1\n",
    "        print(\"maxexecution=\" + str(max_execution))\n",
    "        response = athena.get_query_execution(QueryExecutionId=execution_id)  \n",
    "\n",
    "        if 'QueryExecution' in response and \\\n",
    "                'Status' in response['QueryExecution'] and \\\n",
    "                'State' in response['QueryExecution']['Status']:\n",
    "\n",
    "                state = response['QueryExecution']['Status']['State']\n",
    "                print(state)\n",
    "                \n",
    "                if state == 'SUCCEEDED':\n",
    "                    results = athena.get_query_results(QueryExecutionId=execution_id,\n",
    "                                                                MaxResults=1000)  \n",
    "                                                                \n",
    "                    for i in range(1,len(results['ResultSet']['Rows'])):\n",
    "                        query_id_list.extend(re.findall(r'\"([^\"]*)\"',results['ResultSet']['Rows'][i]['Data'][0].get('VarCharValue')))\n",
    "                        \n",
    "                    #print(query_id_list)\n",
    "    \n",
    "                    print(query_id_list[0:5]) \n",
    "                     \n",
    "                elif state == 'FAILED' or state == 'CANCELLED':\n",
    "                    return False\n",
    "                    \n",
    "        time.sleep(30)\n",
    "    \n",
    "    return query_id_list\n",
    "    \n",
    "#Function about split list into chunk\n",
    "def divide_chunks(batch_query_list:list, chunk): \n",
    "\n",
    "    for i in range(0, len(batch_query_list), chunk):  \n",
    "        yield batch_query_list[i:i + chunk] \n",
    "  \n",
    "    \n",
    "def batch_query(batch_query_chunks):\n",
    "    \n",
    "    for j in range(0,len(batch_query_chunks)):\n",
    "        response = athena.batch_get_query_execution(\n",
    "                                    QueryExecutionIds=batch_query_chunks[j]   \n",
    "                                                )\n",
    "\n",
    "        f = open(\"/tmp/csv_file.csv\", \"w+\")\n",
    "        temp_csv_file = csv.writer(f) \n",
    "        temp_csv_file.writerow([\"queryExecutionId\",\"QueryStatement\", \"DataScannedInBytes\", \"TotalExecutionTimeInMillis\" ])\n",
    "        \n",
    "        for i in range(len(response['QueryExecutions'])):\n",
    "            temp_csv_file.writerow(\n",
    "                                    [\n",
    "                            response['QueryExecutions'][i]['QueryExecutionId'],\n",
    "                            response['QueryExecutions'][i]['Query'],\n",
    "                            response['QueryExecutions'][i]['Statistics']['DataScannedInBytes'],\n",
    "                            response['QueryExecutions'][i]['Statistics']['TotalExecutionTimeInMillis']\n",
    "                                    ]\n",
    "                                    )\n",
    "        f.close()            \n",
    "                                    \n",
    "        s3.upload_file('/tmp/csv_file.csv', upload_bucket,'{}-{}-{}.csv'.format(yesterday.year,yesterday.month,yesterday.day))\n",
    "                            \n",
    "            \n",
    "            \n",
    "        \n",
    "    return False\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
