{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import boto3\n",
    "import uuid\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import time\n",
    "import re\n",
    "import csv\n",
    "\n",
    "#Client\n",
    "athena = boto3.client('athena')\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "#Env\n",
    "output_bucket = os.environ['ATHENA_OUTPUT_BUCKET']\n",
    "chunk = os.environ['CHUNK']\n",
    "upload_bucket = os.environ['BUCKET_NAME']\n",
    "\n",
    "#Empty List\n",
    "\n",
    "\n",
    "#Day before yesterday(2)                                             \n",
    "day_before_yesterday = datetime.now() - timedelta(days= 2)\n",
    "\n",
    "#Main Function\n",
    "def lambda_handler(event, context):\n",
    "    \n",
    "    #SQL Query\n",
    "    sql_query = '''\n",
    "        with clordtrail_log AS (\n",
    "            SELECT\n",
    "                json_extract(responseelements,'$.queryExecutionId') AS query_id,\n",
    "                from_iso8601_timestamp(eventtime) AS datetime\n",
    "            FROM    \n",
    "                cloudtrail_logs_909073207319_cloudtrail_log\n",
    "            WHERE   \n",
    "                eventsource='athena.amazonaws.com'\n",
    "                AND eventname='StartQueryExecution'\n",
    "                AND json_extract(responseelements, '$.queryExecutionId') is NOT null\n",
    "                                )\n",
    "            SELECT *\n",
    "            FROM   clordtrail_log \n",
    "            WHERE  date_diff('day', datetime, current_date) = 1\n",
    "                '''\n",
    "    \n",
    "    #Partition\n",
    "    s3_output = 's3://{}/{}/{}/{}/'.format(output_bucket,datetime.now().year,datetime.now().month,datetime.now().day)  \n",
    "    \n",
    "    #Athena Query\n",
    "    batch_query_id = run_query(sql_query,s3_output, max_execution=5)\n",
    "    print(batch_query_id)\n",
    "    print('batch_query_id_total:',len(batch_query_id))\n",
    "    \n",
    "    #batch_get_query_execution limited 50 query id\n",
    "    #Split List into chunk \n",
    "    batch_query_chunks = list(divide_chunks(batch_query_id, int(chunk)))\n",
    "    print(len(batch_query_chunks))\n",
    "    \n",
    "    batch_query(batch_query_chunks)\n",
    "    \n",
    "def run_query(query, s3_output, max_execution=8):\n",
    "    \n",
    "    query_id_list = [ ]\n",
    "    \n",
    "    #Run SQL Query\n",
    "    response = athena.start_query_execution(\n",
    "                                    QueryString=query,\n",
    "                                    ResultConfiguration={\n",
    "                                    'OutputLocation': s3_output\n",
    "                                                        }\n",
    "                                                )\n",
    "\n",
    "    #Query ID\n",
    "    execution_id = response['QueryExecutionId']\n",
    "    \n",
    "    print(\"QueryExecutionId = \" + str(execution_id))\n",
    "    \n",
    "    state  = 'QUEUED'\n",
    "\n",
    "    while (max_execution > 0 and state in ['RUNNING', 'QUEUED']):\n",
    "        max_execution = max_execution - 1\n",
    "        print(\"maxexecution=\" + str(max_execution))\n",
    "        response = athena.get_query_execution(QueryExecutionId=execution_id)  \n",
    "\n",
    "        if 'QueryExecution' in response and \\\n",
    "                'Status' in response['QueryExecution'] and \\\n",
    "                'State' in response['QueryExecution']['Status']:\n",
    "\n",
    "                state = response['QueryExecution']['Status']['State']\n",
    "                print(state)\n",
    "                \n",
    "                if state == 'SUCCEEDED':\n",
    "                    results = athena.get_query_results(QueryExecutionId=execution_id,\n",
    "                                                                MaxResults=1000)  \n",
    "                                                                \n",
    "                    for i in range(1,len(results['ResultSet']['Rows'])):\n",
    "                        query_id_list.extend(re.findall(r'\"([^\"]*)\"',results['ResultSet']['Rows'][i]['Data'][0].get('VarCharValue')))\n",
    "                    \n",
    "                     \n",
    "                elif state == 'FAILED' or state == 'CANCELLED':\n",
    "                    return False\n",
    "                    \n",
    "        time.sleep(30)\n",
    "    \n",
    "    return query_id_list\n",
    "    \n",
    "#Function about split list into chunk\n",
    "def divide_chunks(batch_query_list:list, chunk): \n",
    "\n",
    "    for i in range(0, len(batch_query_list), chunk):  \n",
    "        yield batch_query_list[i:i + chunk] \n",
    "  \n",
    "    \n",
    "def batch_query(batch_query_chunks):\n",
    "    \n",
    "    for j in range(0,len(batch_query_chunks)):\n",
    "        print(batch_query_chunks[j])\n",
    "        response = athena.batch_get_query_execution(\n",
    "                                    QueryExecutionIds=batch_query_chunks[j]\n",
    "                                               )\n",
    "       \n",
    "         \n",
    "        f = open(\"/tmp/csv_file.csv\", \"w+\")\n",
    "        temp_csv_file = csv.writer(f, delimiter='|') \n",
    "        temp_csv_file.writerow([\"Date\", \"QueryExecutionId\", \"State\", \"DataScannedInBytes\", \"TotalExecutionTimeInMillis\", \"QueryStatement\", \"Comment\" ])\n",
    "        \n",
    "        \n",
    "        for i in range(len(response['QueryExecutions'])):\n",
    "            if len(re.findall( r'\\/\\*',response['QueryExecutions'][i]['Query'].replace(' ','').replace('\\n','').replace('\\\"','').replace('|',''))) != 0:\n",
    "                temp_csv_file.writerow(\n",
    "                                    [\n",
    "                            datetime.strftime(day_before_yesterday,'%Y-%m-%d'),\n",
    "                            response['QueryExecutions'][i]['QueryExecutionId'],\n",
    "                            '{}'.format(response['QueryExecutions'][i]['Status']['State']),\n",
    "                            response['QueryExecutions'][i]['Statistics']['DataScannedInBytes'],\n",
    "                            response['QueryExecutions'][i]['Statistics']['TotalExecutionTimeInMillis'],\n",
    "                            '{}'.format(response['QueryExecutions'][i]['Query'].replace(' ','').replace('\\n','').replace('\\\"','').replace('|','')[0:500]),\n",
    "                            1\n",
    "                                    ]\n",
    "                                    )\n",
    "            elif len(re.findall( '\\/\\*',response['QueryExecutions'][i]['Query'].replace(' ','').replace('\\n','').replace('\\\"','').replace('|',''))) != 0:\n",
    "                temp_csv_file.writerow(\n",
    "                                    [\n",
    "                            datetime.strftime(day_before_yesterday,'%Y-%m-%d'),\n",
    "                            response['QueryExecutions'][i]['QueryExecutionId'],\n",
    "                            '{}'.format(response['QueryExecutions'][i]['Status']['State']),\n",
    "                            response['QueryExecutions'][i]['Statistics']['DataScannedInBytes'],\n",
    "                            response['QueryExecutions'][i]['Statistics']['TotalExecutionTimeInMillis'],\n",
    "                            '{}'.format(response['QueryExecutions'][i]['Query'].replace(' ','').replace('\\n','').replace('\\\"','').replace('|','')[0:500]),\n",
    "                            1\n",
    "                                    ]\n",
    "                                    )\n",
    "            else:\n",
    "                temp_csv_file.writerow(\n",
    "                                    [\n",
    "                            datetime.strftime(day_before_yesterday,'%Y-%m-%d'),\n",
    "                            response['QueryExecutions'][i]['QueryExecutionId'],\n",
    "                            '{}'.format(response['QueryExecutions'][i]['Status']['State']),\n",
    "                            response['QueryExecutions'][i]['Statistics']['DataScannedInBytes'],\n",
    "                            response['QueryExecutions'][i]['Statistics']['TotalExecutionTimeInMillis'],\n",
    "                            '{}'.format(response['QueryExecutions'][i]['Query'].replace(' ','').replace('\\n','').replace('\\\"','').replace('|','')[0:500]),\n",
    "                            0\n",
    "                                    ]\n",
    "                                    )\n",
    "                \n",
    "                            \n",
    "                                    \n",
    "        f.close()            \n",
    "                                    \n",
    "        s3.upload_file('/tmp/csv_file.csv', upload_bucket,'Querydate-{}-{}-{}-Uploadtos3Time-{}-{}-{}-{}-{}-{}.csv'.format(day_before_yesterday.year,\\\n",
    "                                                                                                                            day_before_yesterday.month,\\\n",
    "                                                                                                                            day_before_yesterday.day,\\\n",
    "                                                                                                                            datetime.now().year,\\\n",
    "                                                                                                                            datetime.now().month,\\\n",
    "                                                                                                                            datetime.now().day,\\\n",
    "                                                                                                                            datetime.now().hour,\\\n",
    "                                                                                                                            datetime.now().minute,\\\n",
    "                                                                                                                            datetime.now().second))\n",
    "        time.sleep(3)                   \n",
    "            \n",
    "    return False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
